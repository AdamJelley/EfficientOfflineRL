{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kernels import RBF\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = RBF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(4,5)\n",
    "Y = torch.randn(8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K(X,Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4335,  0.5734,  0.0320, -1.6215, -1.4939],\n",
       "        [-0.1914, -0.1111,  0.8338,  0.2083, -0.3777],\n",
       "        [-0.2607, -1.0506,  0.0431, -0.1642,  0.5468],\n",
       "        [-0.0816, -0.8182,  0.3603,  0.6003, -0.8229]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0108, 0.0016, 0.0031],\n",
       "        [0.0108, 1.0000, 0.2090, 0.5068],\n",
       "        [0.0016, 0.2090, 1.0000, 0.1914],\n",
       "        [0.0031, 0.5068, 0.1914, 1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4444,  1.2142,  2.0666,  0.2998, -0.2833],\n",
       "        [-0.9098, -0.8398, -0.5643, -1.2406,  0.7542],\n",
       "        [ 0.2916,  0.9453,  0.0495,  0.4850,  0.7981],\n",
       "        [-1.7931, -0.5190,  0.2280,  0.3369, -1.2903],\n",
       "        [-0.0423,  2.1562,  0.0412,  0.6128, -0.2299],\n",
       "        [ 0.0770, -0.0808, -0.2820,  0.0927, -0.1821],\n",
       "        [-0.7883,  0.3864,  1.6741,  0.2237, -0.6312],\n",
       "        [-0.5955, -0.4297,  0.8611, -1.2079, -0.0347]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, ensemble_size: int):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.ensemble_size = ensemble_size\n",
    "\n",
    "        self.weight = nn.Parameter(torch.empty(ensemble_size, in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.empty(ensemble_size, 1, out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # default pytorch init for nn.Linear module\n",
    "        for layer in range(self.ensemble_size):\n",
    "            nn.init.kaiming_uniform_(self.weight[layer], a=math.sqrt(5))\n",
    "\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight[0])\n",
    "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # input: [ensemble_size, batch_size, input_size]\n",
    "        # weight: [ensemble_size, input_size, out_size]\n",
    "        # out: [ensemble_size, batch_size, out_size]\n",
    "        return x @ self.weight + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim: int, action_dim: int, hidden_dim: int, num_critics: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            VectorizedLinear(state_dim + action_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, 1, num_critics),\n",
    "        )\n",
    "        # init as in the EDAC paper\n",
    "        for layer in self.critic[::2]:\n",
    "            torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "        torch.nn.init.uniform_(self.critic[-1].weight, -3e-3, 3e-3)\n",
    "        torch.nn.init.uniform_(self.critic[-1].bias, -3e-3, 3e-3)\n",
    "\n",
    "        self.num_critics = num_critics\n",
    "\n",
    "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
    "        # [..., batch_size, state_dim + action_dim]\n",
    "        state_action = torch.cat([state, action], dim=-1)\n",
    "        if state_action.dim() != 3:\n",
    "            assert state_action.dim() == 2\n",
    "            # [num_critics, batch_size, state_dim + action_dim]\n",
    "            state_action = state_action.unsqueeze(0).repeat_interleave(\n",
    "                self.num_critics, dim=0\n",
    "            )\n",
    "        assert state_action.dim() == 3\n",
    "        assert state_action.shape[0] == self.num_critics\n",
    "        # [num_critics, batch_size]\n",
    "        q_values = self.critic(state_action).squeeze(-1)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = VectorizedCritic(\n",
    "        17, 6, 256, 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "for parameters in critic.parameters():\n",
    "    parameters=parameters.reshape(10,-1)\n",
    "    kernel_values = K(parameters, parameters.detach())\n",
    "    print(kernel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = torch.cat([parameters.reshape(10,-1) for parameters in critic.parameters()], dim=1)\n",
    "kernel_values = K(all_parameters, all_parameters.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_grads = torch.autograd.grad(kernel_values.sum(), all_parameters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_grads[0].mean(0).shape\n",
    "# kernel_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_grads[0].shape\n",
    "all_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 6])\n",
      "torch.Size([3, 10, 17])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 17 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(actions\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(states\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m currentQ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([states, actions], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m indices\u001b[39m=\u001b[39mcurrentQ\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindices\n\u001b[1;32m      7\u001b[0m states[\u001b[39m0\u001b[39m,\u001b[39m15\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 17 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.stack([torch.randn(6) for i in range(10)], dim=0) for i in range(3)], dim=0)\n",
    "states = torch.stack([torch.randn(17).repeat(10, 1) for i in range(3)], dim=0)\n",
    "print(actions.shape)\n",
    "print(states.shape)\n",
    "currentQ = torch.cat([states, actions], dim=1).mean(0, keepdim=True)\n",
    "indices=currentQ.max(1).indices\n",
    "states[0,15]\n",
    "states[0,indices]\n",
    "#indices=currentQ.max(dim=1).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(\n",
    "        critic.parameters(), lr=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "type(optimizer.param_groups[0]['params'])\n",
    "param_grads = [param.grad for param in optimizer.param_groups[0]['params']]\n",
    "print(param_grads[0])\n",
    "optimizer.zero_grad()\n",
    "for param in optimizer.param_groups[0]['params']:\n",
    "    param.grad = torch.ones_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer\u001b[39m.\u001b[39;49mparam_groups[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mgrad\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"params\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_grad = torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "all_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (448636623.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[103], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    torch.cat([param.grad.reshape(10,-1) for param in optimizer.param_groups[0]['params']], dim=1) = all_grad\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "torch.cat([param.grad.reshape(10,-1) for param in optimizer.param_groups[0]['params']], dim=1) = all_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = torch.cat([parameters.reshape(10,-1) for parameters in optimizer.param_groups[0]['params']], dim=1).retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1)\n",
    "q_values = critic(states, actions)\n",
    "print(q_values.shape)\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "[param.retain_grad() for param in optimizer.param_groups[0]['params']]\n",
    "critic_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_values = critic(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = torch.cat(\n",
    "            [\n",
    "                parameters.reshape(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def phi(self, loss):\n",
    "        params = self.params.detach().requires_grad_(True)\n",
    "        print(params.shape)\n",
    "        print(loss.shape)\n",
    "\n",
    "        score_function = torch.autograd.grad(loss, params)[0]\n",
    "\n",
    "        K_params = self.K(params, params.detach())\n",
    "        grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def step(self, loss):\n",
    "        self.optim.zero_grad()\n",
    "        self.params.grad = -self.phi(loss)\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.retain_grad() for param in critic.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0002,  0.0002,  0.0002,  ..., -0.0003, -0.0002,  0.0001]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [param for param in critic.parameters()][0]\n",
    "param.grad.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         parameters\u001b[39m.\u001b[39mreshape(\u001b[39m10\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m         \u001b[39mfor\u001b[39;00m parameters \u001b[39min\u001b[39;00m optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     ],\n\u001b[1;32m      6\u001b[0m     dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\u001b[39m.\u001b[39mretain_grad()\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(params\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "params = torch.cat(\n",
    "    [\n",
    "        parameters.reshape(10, -1)\n",
    "        for parameters in optimizer.param_groups[0][\"params\"]\n",
    "    ],\n",
    "    dim=1,\n",
    ").retain_grad()\n",
    "print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = torch.cat([parameters.reshape(10,-1) for parameters in critic.parameters()], dim=1)\n",
    "#params = params.detach().requires_grad_(True)\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "critic_loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n"
     ]
    }
   ],
   "source": [
    "print(critic.parameters().__next__().grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 23, 256])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"params\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_params = self.K(params, params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = torch.cat(\n",
    "            [\n",
    "                parameters.view(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def backward(self, loss_function, **args):\n",
    "        loss = loss_function(**args)\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        score_function = torch.cat(\n",
    "            [\n",
    "                parameters.grad.reshape(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        params = self.params.detach().requires_grad_(True)\n",
    "\n",
    "        K_params = self.K(params, params.detach())\n",
    "        grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        phi = score_function\n",
    "\n",
    "        self.phi = phi\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def step(self):\n",
    "        self.optim.zero_grad()\n",
    "        self.params.grad = -self.phi\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(\n",
    "        critic.parameters(), lr=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(6.7218e-07)\n",
      "tensor(6.7218e-07)\n",
      "tensor(6.7218e-07)\n",
      "tensor(0.)\n",
      "tensor(6.7218e-07)\n"
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "\n",
    "critic_loss.backward()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "score_function = [deepcopy(param.grad) for param in optimizer.param_groups[0]['params']]\n",
    "print(score_function[0].mean())\n",
    "optimizer.zero_grad()\n",
    "print(score_function[0].mean())\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "for param, phi in zip(optimizer.param_groups[0]['params'], score_function):\n",
    "    param.grad = phi\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][0].view(10,-1).matmul(optimizer.param_groups[0]['params'][0].view(10,-1).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 5888])\n",
      "torch.Size([10, 137985])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5888) must match the size of tensor b (137985) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[211], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(score[layer]\u001b[39m.\u001b[39mview(\u001b[39m10\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(grad_K\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m phi \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 15\u001b[0m     K_params\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mmatmul(score[layer]\u001b[39m.\u001b[39;49mview(\u001b[39m10\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)) \u001b[39m+\u001b[39;49m grad_K\n\u001b[1;32m     16\u001b[0m ) \u001b[39m/\u001b[39m params\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5888) must match the size of tensor b (137985) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "all_params =torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).detach().requires_grad_(True)\n",
    "score = [deepcopy(param.grad) for param in optimizer.param_groups[0]['params']]\n",
    "\n",
    "\n",
    "K_params = K(all_params, all_params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), all_params)[0]\n",
    "\n",
    "for layer, params in enumerate(optimizer.param_groups[0]['params']):\n",
    "    shape = params.shape\n",
    "\n",
    "    print(K_params.shape)\n",
    "    print(score[layer].view(10,-1).shape)\n",
    "    print(grad_K.shape)\n",
    "    phi = (\n",
    "        K_params.detach().matmul(score[layer].view(10, -1)) + grad_K\n",
    "    ) / params.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 23, 256])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3,4])\n",
    "torch.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = [param for param in self.optim.param_groups[0][\"params\"]]\n",
    "\n",
    "    def backward(self, loss_function, **args):\n",
    "        loss = loss_function(**args)\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        score = [deepcopy(param.grad) for param in self.params]\n",
    "        phi_all = []\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        for layer, params in enumerate(self.params):\n",
    "            shape = params.shape\n",
    "            params = params.view(10, -1).detach().requires_grad_(True)\n",
    "\n",
    "            K_params = self.K(params, params.detach())\n",
    "            grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "            phi = (\n",
    "                K_params.detach().matmul(score[layer].reshape(10, -1)) + grad_K\n",
    "            ) / params.size(0)\n",
    "\n",
    "            phi_all.append(phi.reshape(shape))\n",
    "        # params = [param.view(10,-1).detach().requires_grad_(True) for param in self.params]\n",
    "\n",
    "        # K_params = self.K(params, params.detach())\n",
    "        # grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        # phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        self.phi = phi_all\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "torch.Size([10, 137985])\n",
      "tensor(1.2654e-13)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "params = torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "params.retain_grad()\n",
    "K_params = K(params, params.detach())\n",
    "K_params.sum().backward()\n",
    "print(params.grad.shape)\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "grads = [param.grad for param in optimizer.param_groups[0]['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-9.4986e-07)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "params = torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "params.retain_grad()\n",
    "\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1)\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "critic_loss.backward()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n"
     ]
    }
   ],
   "source": [
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([10, 23, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 1]),\n",
       " torch.Size([10, 1, 1])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = [param.shape for param in optimizer.param_groups[0]['params']]\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5888, 256, 65536, 256, 65536, 256, 256, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = tuple([int(param.numel()/10) for param in optimizer.param_groups[0]['params']])\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-0.0002)\n",
      "tensor(-3.1934e-05)\n",
      "tensor(-3.1934e-05)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "critic_loss.backward()\n",
    "\n",
    "score = torch.cat([param.grad.view(param.size(0),-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "print(score.mean())\n",
    "optimizer.zero_grad()\n",
    "\n",
    "params=torch.cat([param.view(param.size(0),-1) for param in optimizer.param_groups[0]['params']], dim=1).detach().requires_grad_()\n",
    "K_params = K(params, params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "phi = (\n",
    "    K_params.detach().matmul(score) + grad_K\n",
    ") / params.size(0)\n",
    "print(phi.mean())\n",
    "\n",
    "lengths = tuple([int(param.numel()/param.size(0)) for param in optimizer.param_groups[0]['params']])\n",
    "\n",
    "for param, phi in zip(optimizer.param_groups[0]['params'], torch.split(phi, lengths, dim=1)):\n",
    "    param.grad = phi.reshape(param.shape)\n",
    "print(torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 1])\n",
      "torch.Size([10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for tensor, shape in zip(torch.split(params, lengths, dim=1), shapes):\n",
    "    tensor=tensor.reshape(shape)\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\n\u001b[1;32m      7\u001b[0m TensorBatch \u001b[39m=\u001b[39m List[torch\u001b[39m.\u001b[39mTensor]\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdiscount_cumsum\u001b[39m(x, discount):\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m _ERROR_MESSAGE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWarning: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlocomotion\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhand_manipulation_suite\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpointmaze\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/locomotion/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistration\u001b[39;00m \u001b[39mimport\u001b[39;00m register\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlocomotion\u001b[39;00m \u001b[39mimport\u001b[39;00m ant\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlocomotion\u001b[39;00m \u001b[39mimport\u001b[39;00m maze_env\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mregister(\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m    id='antmaze-umaze-v0',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/locomotion/ant.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder\u001b[39;00m \u001b[39mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerated\u001b[39;00m \u001b[39mimport\u001b[39;00m const\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmjrenderpool\u001b[39;00m \u001b[39mimport\u001b[39;00m MjRenderPool\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:504\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m__fun\n\u001b[1;32m    503\u001b[0m mujoco_path \u001b[39m=\u001b[39m discover_mujoco()\n\u001b[0;32m--> 504\u001b[0m cymj \u001b[39m=\u001b[39m load_cython_ext(mujoco_path)\n\u001b[1;32m    507\u001b[0m \u001b[39m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdict2\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:74\u001b[0m, in \u001b[0;36mload_cython_ext\u001b[0;34m(mujoco_path)\u001b[0m\n\u001b[1;32m     72\u001b[0m     Builder \u001b[39m=\u001b[39m MacExtensionBuilder\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlinux\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     _ensure_set_env_var(\u001b[39m\"\u001b[39;49m\u001b[39mLD_LIBRARY_PATH\u001b[39;49m\u001b[39m\"\u001b[39;49m, lib_path)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mMUJOCO_PY_FORCE_CPU\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_nvidia_lib_dir() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         _ensure_set_env_var(\u001b[39m\"\u001b[39m\u001b[39mLD_LIBRARY_PATH\u001b[39m\u001b[39m\"\u001b[39m, get_nvidia_lib_dir())\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:120\u001b[0m, in \u001b[0;36m_ensure_set_env_var\u001b[0;34m(var_name, lib_path)\u001b[0m\n\u001b[1;32m    118\u001b[0m paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(path) \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m paths]\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m lib_path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMissing path to your environment variable. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mCurrent values \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mPlease add following line to .bashrc:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mexport \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=$\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (var_name, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(var_name, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    124\u001b[0m                                           var_name, var_name, lib_path))\n",
      "\u001b[0;31mException\u001b[0m: \nMissing path to your environment variable. \nCurrent values LD_LIBRARY_PATH=\nPlease add following line to .bashrc:\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import d4rl\n",
    "\n",
    "TensorBatch = List[torch.Tensor]\n",
    "\n",
    "def discount_cumsum(x, discount):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0] - 1)):\n",
    "        disc_cumsum[t] = x[t] + discount * disc_cumsum[t + 1]\n",
    "    return disc_cumsum\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "        buffer_size: int,\n",
    "        discount: float,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        self._buffer_size = buffer_size\n",
    "        self._pointer = 0\n",
    "        self._size = 0\n",
    "\n",
    "        self._states = torch.zeros(\n",
    "            (buffer_size, state_dim), dtype=torch.float32, device=device\n",
    "        )\n",
    "        self._actions = torch.zeros(\n",
    "            (buffer_size, action_dim), dtype=torch.float32, device=device\n",
    "        )\n",
    "        self._rewards = torch.zeros((buffer_size, 1), dtype=torch.float32, device=device)\n",
    "        self._returns = torch.zeros((buffer_size, 1), dtype=torch.float32, device=device)\n",
    "        self._next_states = torch.zeros(\n",
    "            (buffer_size, state_dim), dtype=torch.float32, device=device\n",
    "        )\n",
    "        self._dones = torch.zeros((buffer_size, 1), dtype=torch.float32, device=device)\n",
    "        self._discount = discount\n",
    "        self._device = device\n",
    "\n",
    "    def _to_tensor(self, data: np.ndarray) -> torch.Tensor:\n",
    "        return torch.tensor(data, dtype=torch.float32, device=self._device)\n",
    "\n",
    "    # Loads data in d4rl format, i.e. from Dict[str, np.array].\n",
    "    def load_d4rl_dataset(self, data: Dict[str, np.ndarray]):\n",
    "        if self._size != 0:\n",
    "            raise ValueError(\"Trying to load data into non-empty replay buffer\")\n",
    "        n_transitions = data[\"observations\"].shape[0]\n",
    "        if n_transitions > self._buffer_size:\n",
    "            raise ValueError(\n",
    "                \"Replay buffer is smaller than the dataset you are trying to load!\"\n",
    "            )\n",
    "        self._states[:n_transitions] = self._to_tensor(data[\"observations\"])\n",
    "        self._actions[:n_transitions] = self._to_tensor(data[\"actions\"])\n",
    "        self._rewards[:n_transitions] = self._to_tensor(data[\"rewards\"][..., None])\n",
    "        self._returns[:n_transitions] = self._to_tensor(discount_cumsum(data[\"rewards\"], self._discount)[..., None])\n",
    "        self._next_states[:n_transitions] = self._to_tensor(data[\"next_observations\"])\n",
    "        self._dones[:n_transitions] = self._to_tensor(data[\"terminals\"][..., None])\n",
    "        self._size += n_transitions\n",
    "        self._pointer = min(self._size, n_transitions)\n",
    "\n",
    "        print(f\"Dataset size: {n_transitions}\")\n",
    "        print(data[\"rewards\"].shape)\n",
    "\n",
    "    def sample(self, batch_size: int) -> TensorBatch:\n",
    "        indices = np.random.randint(0, min(self._size, self._pointer), size=batch_size)\n",
    "        states = self._states[indices]\n",
    "        actions = self._actions[indices]\n",
    "        rewards = self._rewards[indices]\n",
    "        returns = self._returns[indices]\n",
    "        next_states = self._next_states[indices]\n",
    "        dones = self._dones[indices]\n",
    "        return [states, actions, rewards, returns, next_states, dones]\n",
    "\n",
    "    def add_transition(self):\n",
    "        # Use this method to add new data into the replay buffer during fine-tuning.\n",
    "        # I left it unimplemented since now we do not do fine-tuning.\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(states: np.ndarray, eps: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    mean = states.mean(0)\n",
    "    std = states.std(0) + eps\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def normalize_states(states: np.ndarray, mean: np.ndarray, std: np.ndarray):\n",
    "    return (states - mean) / std\n",
    "\n",
    "def discount_cumsum(x, discount):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0] - 1)):\n",
    "        disc_cumsum[t] = x[t] + discount * disc_cumsum[t + 1]\n",
    "    return disc_cumsum\n",
    "\n",
    "\n",
    "def wrap_env(\n",
    "    env: gym.Env,\n",
    "    state_mean: Union[np.ndarray, float] = 0.0,\n",
    "    state_std: Union[np.ndarray, float] = 1.0,\n",
    "    reward_scale: float = 1.0,\n",
    ") -> gym.Env:\n",
    "    # PEP 8: E731 do not assign a lambda expression, use a def\n",
    "    def normalize_state(state):\n",
    "        return (\n",
    "            state - state_mean\n",
    "        ) / state_std  # epsilon should be already added in std.\n",
    "\n",
    "    def scale_reward(reward):\n",
    "        # Please be careful, here reward is multiplied by scale!\n",
    "        return reward_scale * reward\n",
    "\n",
    "    env = gym.wrappers.TransformObservation(env, normalize_state)\n",
    "    if reward_scale != 1.0:\n",
    "        env = gym.wrappers.TransformReward(env, scale_reward)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error. Trying to rebuild mujoco_py.\n",
      "running build_ext\n",
      "building 'mujoco_py.cymj' extension\n",
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py -I/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/numpy/core/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/vendor/egl -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/include/python3.10 -c /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.c -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.o -fopenmp -w\n",
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py -I/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/numpy/core/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/vendor/egl -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/include/python3.10 -c /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.c -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.o -fopenmp -w\n",
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -shared -Wl,-rpath,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath-link,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -L/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath-link,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -L/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.o -L/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin -Wl,-R/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin -lmujoco210 -lglewegl -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py/cymj.cpython-310-x86_64-linux-gnu.so -fopenmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Mujoco-based envs failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "libglewegl.so: cannot open shared object file: No such file or directory\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/glfw/__init__.py:912: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error. Trying to rebuild mujoco_py.\n",
      "running build_ext\n",
      "building 'mujoco_py.cymj' extension\n",
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py -I/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/numpy/core/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/vendor/egl -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/include/python3.10 -c /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.c -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.o -fopenmp -w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Jan  4 2023 11:33:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -O2 -isystem /disk/scratch1/adamjelley/miniconda3/envs/CORL/include -fPIC -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py -I/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/numpy/core/include -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/vendor/egl -I/disk/scratch1/adamjelley/miniconda3/envs/CORL/include/python3.10 -c /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.c -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.o -fopenmp -w\n",
      "gcc -pthread -B /disk/scratch1/adamjelley/miniconda3/envs/CORL/compiler_compat -shared -Wl,-rpath,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath-link,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -L/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -Wl,-rpath-link,/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib -L/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/cymj.o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-310/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/gl/eglshim.o -L/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin -Wl,-R/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin -lmujoco210 -lglewegl -o /disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_310_linuxgpuextensionbuilder/lib.linux-x86_64-cpython-310/mujoco_py/cymj.cpython-310-x86_64-linux-gnu.so -fopenmp\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder\u001b[39;00m \u001b[39mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerated\u001b[39;00m \u001b[39mimport\u001b[39;00m const\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:504\u001b[0m\n\u001b[1;32m    503\u001b[0m mujoco_path \u001b[39m=\u001b[39m discover_mujoco()\n\u001b[0;32m--> 504\u001b[0m cymj \u001b[39m=\u001b[39m load_cython_ext(mujoco_path)\n\u001b[1;32m    507\u001b[0m \u001b[39m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:111\u001b[0m, in \u001b[0;36mload_cython_ext\u001b[0;34m(mujoco_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m         cext_so_path \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mbuild()\n\u001b[0;32m--> 111\u001b[0m         mod \u001b[39m=\u001b[39m load_dynamic_ext(\u001b[39m'\u001b[39;49m\u001b[39mcymj\u001b[39;49m\u001b[39m'\u001b[39;49m, cext_so_path)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m mod\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:130\u001b[0m, in \u001b[0;36mload_dynamic_ext\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    129\u001b[0m loader \u001b[39m=\u001b[39m ExtensionFileLoader(name, path)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mload_module()\n",
      "\u001b[0;31mImportError\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m env_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhalfcheetah-medium-v2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m buffer_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m2_000_000\u001b[39m  \u001b[39m# Replay buffer size\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/__init__.py:47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgym_bullet\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39md4rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpointmaze_bullet\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SUPPRESS_MESSAGES:\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/pointmaze_bullet/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpointmaze\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmaze_model\u001b[39;00m \u001b[39mimport\u001b[39;00m OPEN, U_MAZE, MEDIUM_MAZE, LARGE_MAZE, U_MAZE_EVAL, MEDIUM_MAZE_EVAL, LARGE_MAZE_EVAL\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistration\u001b[39;00m \u001b[39mimport\u001b[39;00m register\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39md4rl\u001b[39;00m \u001b[39mimport\u001b[39;00m infos\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/pointmaze/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmaze_model\u001b[39;00m \u001b[39mimport\u001b[39;00m MazeEnv, OPEN, U_MAZE, MEDIUM_MAZE, LARGE_MAZE, U_MAZE_EVAL, MEDIUM_MAZE_EVAL, LARGE_MAZE_EVAL\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistration\u001b[39;00m \u001b[39mimport\u001b[39;00m register\n\u001b[1;32m      4\u001b[0m register(\n\u001b[1;32m      5\u001b[0m     \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaze2d-open-v0\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     entry_point\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39md4rl.pointmaze:MazeEnv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/d4rl/pointmaze/maze_model.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\" A pointmass maze env.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m \u001b[39mimport\u001b[39;00m mujoco_env\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39md4rl\u001b[39;00m \u001b[39mimport\u001b[39;00m offline_env\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco_env\u001b[39;00m \u001b[39mimport\u001b[39;00m MujocoEnv\n\u001b[1;32m      3\u001b[0m \u001b[39m# ^^^^^ so that user gets the correct error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# message if mujoco is not installed correctly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mant\u001b[39;00m \u001b[39mimport\u001b[39;00m AntEnv\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     15\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m             e\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m DEFAULT_SIZE \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_observation_to_space\u001b[39m(observation):\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import d4rl\n",
    "\n",
    "env_name = \"halfcheetah-medium-v2\"\n",
    "buffer_size: int = 2_000_000  # Replay buffer size\n",
    "batch_size: int = 256  # Batch size for all networks\n",
    "discount: float = 0.99\n",
    "device=\"cuda\"\n",
    "    \n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "\n",
    "dataset = d4rl.qlearning_dataset(env)\n",
    "\n",
    "\n",
    "state_mean, state_std = compute_mean_std(dataset[\"observations\"], eps=1e-3)\n",
    "\n",
    "\n",
    "dataset[\"observations\"] = normalize_states(\n",
    "    dataset[\"observations\"], state_mean, state_std\n",
    ")\n",
    "dataset[\"next_observations\"] = normalize_states(\n",
    "    dataset[\"next_observations\"], state_mean, state_std\n",
    ")\n",
    "env = wrap_env(env, state_mean=state_mean, state_std=state_std)\n",
    "replay_buffer = ReplayBuffer(\n",
    "    state_dim,\n",
    "    action_dim,\n",
    "    buffer_size,\n",
    "    discount,\n",
    "    device,\n",
    ")\n",
    "replay_buffer.load_d4rl_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin:/usr/lib/nvidia\n"
     ]
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH=:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin:/usr/lib/nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANPATH=/opt/texlive/2019/texmf-dist/doc/man:\n",
      "XDG_SESSION_ID=13546\n",
      "ROLES=anccs-user bayeswatch-member cdtcluster-visitor cohort-pgr degree-phd dice-account-holder homepagescgiuser homepagesuser homepageswebuser ianc-member marker-mlpr person session20-start student teachingsupport tutor-mlpr\n",
      "VIRTUALENVWRAPPER_SCRIPT=/usr/bin/virtualenvwrapper.sh\n",
      "TERM=xterm-color\n",
      "SHELL=/bin/bash\n",
      "CLICOLOR=1\n",
      "SSH_CLIENT=2001:630:3c1:125::1031 56761 22\n",
      "CONDA_SHLVL=2\n",
      "PYTHONUNBUFFERED=1\n",
      "BASH=/bin/bash\n",
      "CONDA_PROMPT_MODIFIER=(CORL) \n",
      "QTDIR=/usr/lib64/qt-3.3\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "QTINC=/usr/lib64/qt-3.3/include\n",
      "VSCODE_HANDLES_SIGPIPE=true\n",
      "QT_GRAPHICSSYSTEM_CHECKED=1\n",
      "PYTHONIOENCODING=utf-8\n",
      "USER=s2139934\n",
      "CONDA_EXE=/disk/scratch1/adamjelley/miniconda3/bin/conda\n",
      "JPY_PARENT_PID=124693\n",
      "PAGER=cat\n",
      "ELECTRON_RUN_AS_NODE=1\n",
      "VSCODE_AMD_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess\n",
      "JUPYTER_PATH=/disk/scratch1/adamjelley/.vscode-server/extensions/ms-toolsai.jupyter-2023.1.2010391206/temp/jupyter\n",
      "VSCODE_AGENT_FOLDER=/disk/scratch1/adamjelley//.vscode-server\n",
      "_CE_CONDA=\n",
      "XPRINTER=xp_ps_spooldir_tmp_Xprintjobs\n",
      "CONDA_ROOT=/disk/scratch1/adamjelley/miniconda3\n",
      "CONDA_PREFIX_1=/disk/scratch1/adamjelley/miniconda3\n",
      "PATH=/disk/scratch1/adamjelley/miniconda3/envs/CORL/bin:/disk/scratch1/adamjelley/.vscode-server/bin/441438abd1ac652551dbe4d408dfcec8a499b8bf/bin/remote-cli:/opt/mendeleydesktop/bin:/usr/lib64/qt-3.3/bin:/opt/mendeleydesktop/bin:/disk/scratch1/adamjelley/miniconda3/condabin:/usr/local/bin:/usr/lib/jvm/java-1.8.0/bin:/opt/texlive/2019/bin/x86_64-linux:/usr/local/sbin:/usr/bin:/sbin:/usr/pgsql-12/bin:/opt/cuda/bin:/opt/sicstus-4.0.1/bin:/opt/cuda/bin\n",
      "MAIL=/var/mail/s2139934\n",
      "PYGAME_HIDE_SUPPORT_PROMPT=hide\n",
      "_=/usr/bin/printenv\n",
      "CONDA_PREFIX=/disk/scratch1/adamjelley/miniconda3/envs/CORL\n",
      "PWD=/disk/scratch1/adamjelley/CORL\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS=true\n",
      "CRICHTON_SYS=/etc/crichton.d\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "EDITOR=/usr/bin/emacs\n",
      "LANG=en_GB.UTF-8\n",
      "MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles\n",
      "LOADEDMODULES=\n",
      "FORCE_COLOR=1\n",
      "KRB5CCNAME=FILE:/tmp/krb5cc_2536453_HpoRsF\n",
      "ENVIRONMENT=el7\n",
      "_CE_M=\n",
      "SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass\n",
      "HOME=/afs/inf.ed.ac.uk/user/s21/s2139934\n",
      "SHLVL=7\n",
      "VSCODE_NLS_CONFIG={\"locale\":\"en\",\"availableLanguages\":{}}\n",
      "MAPPATH=/etc/amd:/etc\n",
      "_VIRTUALENVWRAPPER_API= mkvirtualenv rmvirtualenv lsvirtualenv showvirtualenv workon add2virtualenv cdsitepackages cdvirtualenv lssitepackages toggleglobalsitepackages cpvirtualenv setvirtualenvproject mkproject cdproject mktmpenv wipeenv allvirtualenv mkvirtualenv rmvirtualenv lsvirtualenv showvirtualenv workon add2virtualenv cdsitepackages cdvirtualenv lssitepackages toggleglobalsitepackages cpvirtualenv setvirtualenvproject mkproject cdproject mktmpenv wipeenv allvirtualenv\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1\n",
      "ASPELL_CONF=master british\n",
      "LOGNAME=s2139934\n",
      "CONDA_PYTHON_EXE=/disk/scratch1/adamjelley/miniconda3/bin/python\n",
      "CVS_RSH=ssh\n",
      "QTLIB=/usr/lib64/qt-3.3/lib\n",
      "SSH_CONNECTION=2001:630:3c1:125::1031 56761 2001:630:3c1:32:e9d:92ff:fec5:828b 22\n",
      "XDG_DATA_DIRS=/afs/inf.ed.ac.uk/user/s21/s2139934/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share\n",
      "VSCODE_IPC_HOOK_CLI=/run/user/2536453/vscode-ipc-e651fc1c-f355-425d-92be-f155a4b8e802.sock\n",
      "MODULESHOME=/usr/share/Modules\n",
      "CLICOLOR_FORCE=1\n",
      "LESSOPEN=||/usr/bin/lesspipe.sh %s\n",
      "CONDA_DEFAULT_ENV=CORL\n",
      "BROWSER=/disk/scratch1/adamjelley/.vscode-server/bin/441438abd1ac652551dbe4d408dfcec8a499b8bf/bin/helpers/browser.sh\n",
      "ENV_ROOT=/usr/share/defenv/bash\n",
      "INFOPATH=/opt/texlive/2019/texmf-dist/doc/info:\n",
      "IDEA_JDK=/usr/lib/jvm/java-sun\n",
      "XDG_RUNTIME_DIR=/run/user/2536453\n",
      "CRICHTON_USR=/afs/inf.ed.ac.uk/user/s21/s2139934/.crichton.d\n",
      "GIT_PAGER=cat\n",
      "VSCODE_CWD=/afs/inf.ed.ac.uk/user/s21/s2139934\n",
      "SshAgent=/usr/bin/ssh-agent\n",
      "SHORT_HOSTNAME=edwards\n",
      "BASH_FUNC_resize()=() {  eval `command resize`\n",
      "}\n",
      "BASH_FUNC_setpath()=() {  if [ -f /usr/bin/pathfix ]; then\n",
      " pathfix_binary=/usr/bin/pathfix;\n",
      " else\n",
      " pathfix_binary=/usr/local/bin/pathfix;\n",
      " fi;\n",
      " new_PATH=`$pathfix_binary $@`;\n",
      " [ \"$new_PATH\" ] && PATH=\"$new_PATH\";\n",
      " export PATH\n",
      "}\n",
      "BASH_FUNC_setup()=() {  source /usr/local/share/setup/setup.sh $*\n",
      "}\n",
      "BASH_FUNC_purge()=() {  rm -f *~ .*~ \\#*\\# tmp*\n",
      "}\n",
      "BASH_FUNC_command_not_found_handle()=() {  unset command_not_found_handle;\n",
      " if [[ \"$IFS\" != ' \t\n",
      "' ]]; then\n",
      " _command_not_found $*;\n",
      " fi;\n",
      " function dbg () \n",
      " { \n",
      " [[ -n $CRICHTON_DEBUG ]] && echo $1 1>&2\n",
      " };\n",
      " SORT=\"/usr/bin/_SortBashRC\";\n",
      " PATTERN='[0-9][0-9][0-9].*';\n",
      " if [[ -n $CRICHTON_DEBUG ]]; then\n",
      " modules=$($SORT /etc/crichton.d/$PATTERN /afs/inf.ed.ac.uk/user/s21/s2139934/.crichton.d/$PATTERN);\n",
      " else\n",
      " modules=$($SORT /etc/crichton.d/$PATTERN /afs/inf.ed.ac.uk/user/s21/s2139934/.crichton.d/$PATTERN 2>&-);\n",
      " fi;\n",
      " dbg \"- Found $(/bin/echo $modules | /usr/bin/wc -w 2>&-) modules.\";\n",
      " for mod in ${modules} _command_not_found;\n",
      " do\n",
      " dbg \"-- $(/bin/basename $mod 2>&-)\";\n",
      " CRICHTON_SYS=/etc/crichton.d CRICHTON_USR=/afs/inf.ed.ac.uk/user/s21/s2139934/.crichton.d \"$mod\" $*;\n",
      " exit=$?;\n",
      " dbg \"[exit $exit]\";\n",
      " [[ $exit == 255 ]] && { \n",
      " _command_not_found $1;\n",
      " break\n",
      " };\n",
      " [[ $exit == 0 ]] && break;\n",
      " done;\n",
      " return 127\n",
      "}\n",
      "BASH_FUNC_colloq()=() {  more /usr/local/alert/misc/coll\n",
      "}\n",
      "BASH_FUNC_module()=() {  eval `/usr/bin/modulecmd bash $*`\n",
      "}\n",
      "BASH_FUNC_gnu()=() {  command gnu -u s2139934 $*\n",
      "}\n",
      "BASH_FUNC__command_not_found()=() {  echo \"bash: $1: command not found\" 1>&2\n",
      "}\n",
      "BASH_FUNC_rvirsh()=() {  KVMHOST=$1;\n",
      " shift;\n",
      " if [ \"$KVMHOST\" ]; then\n",
      " if [ \"$KVMHOST\" = \".\" ]; then\n",
      " URI=\"qemu:///system\";\n",
      " else\n",
      " URI=\"qemu+ssh://$KVMHOST/system\";\n",
      " fi;\n",
      " else\n",
      " URI=\"qemu:///system\";\n",
      " fi;\n",
      " virsh --connect $URI $@\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!printenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "173b67b242dc59c580e82c555e2ef8f010d22ca709f837bddfbc98404951b495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
