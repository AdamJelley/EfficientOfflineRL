{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kernels import RBF\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = RBF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(4,5)\n",
    "Y = torch.randn(8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K(X,Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4335,  0.5734,  0.0320, -1.6215, -1.4939],\n",
       "        [-0.1914, -0.1111,  0.8338,  0.2083, -0.3777],\n",
       "        [-0.2607, -1.0506,  0.0431, -0.1642,  0.5468],\n",
       "        [-0.0816, -0.8182,  0.3603,  0.6003, -0.8229]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0108, 0.0016, 0.0031],\n",
       "        [0.0108, 1.0000, 0.2090, 0.5068],\n",
       "        [0.0016, 0.2090, 1.0000, 0.1914],\n",
       "        [0.0031, 0.5068, 0.1914, 1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4444,  1.2142,  2.0666,  0.2998, -0.2833],\n",
       "        [-0.9098, -0.8398, -0.5643, -1.2406,  0.7542],\n",
       "        [ 0.2916,  0.9453,  0.0495,  0.4850,  0.7981],\n",
       "        [-1.7931, -0.5190,  0.2280,  0.3369, -1.2903],\n",
       "        [-0.0423,  2.1562,  0.0412,  0.6128, -0.2299],\n",
       "        [ 0.0770, -0.0808, -0.2820,  0.0927, -0.1821],\n",
       "        [-0.7883,  0.3864,  1.6741,  0.2237, -0.6312],\n",
       "        [-0.5955, -0.4297,  0.8611, -1.2079, -0.0347]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, ensemble_size: int):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.ensemble_size = ensemble_size\n",
    "\n",
    "        self.weight = nn.Parameter(torch.empty(ensemble_size, in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.empty(ensemble_size, 1, out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # default pytorch init for nn.Linear module\n",
    "        for layer in range(self.ensemble_size):\n",
    "            nn.init.kaiming_uniform_(self.weight[layer], a=math.sqrt(5))\n",
    "\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight[0])\n",
    "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # input: [ensemble_size, batch_size, input_size]\n",
    "        # weight: [ensemble_size, input_size, out_size]\n",
    "        # out: [ensemble_size, batch_size, out_size]\n",
    "        return x @ self.weight + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim: int, action_dim: int, hidden_dim: int, num_critics: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            VectorizedLinear(state_dim + action_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, hidden_dim, num_critics),\n",
    "            nn.ReLU(),\n",
    "            VectorizedLinear(hidden_dim, 1, num_critics),\n",
    "        )\n",
    "        # init as in the EDAC paper\n",
    "        for layer in self.critic[::2]:\n",
    "            torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "        torch.nn.init.uniform_(self.critic[-1].weight, -3e-3, 3e-3)\n",
    "        torch.nn.init.uniform_(self.critic[-1].bias, -3e-3, 3e-3)\n",
    "\n",
    "        self.num_critics = num_critics\n",
    "\n",
    "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
    "        # [..., batch_size, state_dim + action_dim]\n",
    "        state_action = torch.cat([state, action], dim=-1)\n",
    "        if state_action.dim() != 3:\n",
    "            assert state_action.dim() == 2\n",
    "            # [num_critics, batch_size, state_dim + action_dim]\n",
    "            state_action = state_action.unsqueeze(0).repeat_interleave(\n",
    "                self.num_critics, dim=0\n",
    "            )\n",
    "        assert state_action.dim() == 3\n",
    "        assert state_action.shape[0] == self.num_critics\n",
    "        # [num_critics, batch_size]\n",
    "        q_values = self.critic(state_action).squeeze(-1)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = VectorizedCritic(\n",
    "        17, 6, 256, 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "for parameters in critic.parameters():\n",
    "    parameters=parameters.reshape(10,-1)\n",
    "    kernel_values = K(parameters, parameters.detach())\n",
    "    print(kernel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = torch.cat([parameters.reshape(10,-1) for parameters in critic.parameters()], dim=1)\n",
    "kernel_values = K(all_parameters, all_parameters.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_grads = torch.autograd.grad(kernel_values.sum(), all_parameters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_grads[0].mean(0).shape\n",
    "# kernel_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_grads[0].shape\n",
    "all_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 6])\n",
      "torch.Size([3, 10, 17])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 17 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(actions\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(states\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m currentQ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([states, actions], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m indices\u001b[39m=\u001b[39mcurrentQ\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindices\n\u001b[1;32m      7\u001b[0m states[\u001b[39m0\u001b[39m,\u001b[39m15\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 17 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.stack([torch.randn(6) for i in range(10)], dim=0) for i in range(3)], dim=0)\n",
    "states = torch.stack([torch.randn(17).repeat(10, 1) for i in range(3)], dim=0)\n",
    "print(actions.shape)\n",
    "print(states.shape)\n",
    "currentQ = torch.cat([states, actions], dim=1).mean(0, keepdim=True)\n",
    "indices=currentQ.max(1).indices\n",
    "states[0,15]\n",
    "states[0,indices]\n",
    "#indices=currentQ.max(dim=1).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(\n",
    "        critic.parameters(), lr=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "type(optimizer.param_groups[0]['params'])\n",
    "param_grads = [param.grad for param in optimizer.param_groups[0]['params']]\n",
    "print(param_grads[0])\n",
    "optimizer.zero_grad()\n",
    "for param in optimizer.param_groups[0]['params']:\n",
    "    param.grad = torch.ones_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer\u001b[39m.\u001b[39;49mparam_groups[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mgrad\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"params\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_grad = torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "all_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (448636623.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[103], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    torch.cat([param.grad.reshape(10,-1) for param in optimizer.param_groups[0]['params']], dim=1) = all_grad\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "torch.cat([param.grad.reshape(10,-1) for param in optimizer.param_groups[0]['params']], dim=1) = all_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = torch.cat([parameters.reshape(10,-1) for parameters in optimizer.param_groups[0]['params']], dim=1).retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1)\n",
    "q_values = critic(states, actions)\n",
    "print(q_values.shape)\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "[param.retain_grad() for param in optimizer.param_groups[0]['params']]\n",
    "critic_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_values = critic(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = torch.cat(\n",
    "            [\n",
    "                parameters.reshape(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def phi(self, loss):\n",
    "        params = self.params.detach().requires_grad_(True)\n",
    "        print(params.shape)\n",
    "        print(loss.shape)\n",
    "\n",
    "        score_function = torch.autograd.grad(loss, params)[0]\n",
    "\n",
    "        K_params = self.K(params, params.detach())\n",
    "        grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def step(self, loss):\n",
    "        self.optim.zero_grad()\n",
    "        self.params.grad = -self.phi(loss)\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.retain_grad() for param in critic.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0002,  0.0002,  0.0002,  ..., -0.0003, -0.0002,  0.0001]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [param for param in critic.parameters()][0]\n",
    "param.grad.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         parameters\u001b[39m.\u001b[39mreshape(\u001b[39m10\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m         \u001b[39mfor\u001b[39;00m parameters \u001b[39min\u001b[39;00m optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     ],\n\u001b[1;32m      6\u001b[0m     dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\u001b[39m.\u001b[39mretain_grad()\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(params\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "params = torch.cat(\n",
    "    [\n",
    "        parameters.reshape(10, -1)\n",
    "        for parameters in optimizer.param_groups[0][\"params\"]\n",
    "    ],\n",
    "    dim=1,\n",
    ").retain_grad()\n",
    "print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = torch.cat([parameters.reshape(10,-1) for parameters in critic.parameters()], dim=1)\n",
    "#params = params.detach().requires_grad_(True)\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "critic_loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n"
     ]
    }
   ],
   "source": [
    "print(critic.parameters().__next__().grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 23, 256])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"params\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_params = self.K(params, params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = torch.cat(\n",
    "            [\n",
    "                parameters.view(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def backward(self, loss_function, **args):\n",
    "        loss = loss_function(**args)\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        score_function = torch.cat(\n",
    "            [\n",
    "                parameters.grad.reshape(10, -1)\n",
    "                for parameters in self.optim.param_groups[0][\"params\"]\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        params = self.params.detach().requires_grad_(True)\n",
    "\n",
    "        K_params = self.K(params, params.detach())\n",
    "        grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        phi = score_function\n",
    "\n",
    "        self.phi = phi\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def step(self):\n",
    "        self.optim.zero_grad()\n",
    "        self.params.grad = -self.phi\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(\n",
    "        critic.parameters(), lr=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(6.7218e-07)\n",
      "tensor(6.7218e-07)\n",
      "tensor(6.7218e-07)\n",
      "tensor(0.)\n",
      "tensor(6.7218e-07)\n"
     ]
    }
   ],
   "source": [
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "\n",
    "critic_loss.backward()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "score_function = [deepcopy(param.grad) for param in optimizer.param_groups[0]['params']]\n",
    "print(score_function[0].mean())\n",
    "optimizer.zero_grad()\n",
    "print(score_function[0].mean())\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "for param, phi in zip(optimizer.param_groups[0]['params'], score_function):\n",
    "    param.grad = phi\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][0].view(10,-1).matmul(optimizer.param_groups[0]['params'][0].view(10,-1).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 5888])\n",
      "torch.Size([10, 137985])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5888) must match the size of tensor b (137985) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[211], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(score[layer]\u001b[39m.\u001b[39mview(\u001b[39m10\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(grad_K\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m phi \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 15\u001b[0m     K_params\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mmatmul(score[layer]\u001b[39m.\u001b[39;49mview(\u001b[39m10\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)) \u001b[39m+\u001b[39;49m grad_K\n\u001b[1;32m     16\u001b[0m ) \u001b[39m/\u001b[39m params\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5888) must match the size of tensor b (137985) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "all_params =torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).detach().requires_grad_(True)\n",
    "score = [deepcopy(param.grad) for param in optimizer.param_groups[0]['params']]\n",
    "\n",
    "\n",
    "K_params = K(all_params, all_params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), all_params)[0]\n",
    "\n",
    "for layer, params in enumerate(optimizer.param_groups[0]['params']):\n",
    "    shape = params.shape\n",
    "\n",
    "    print(K_params.shape)\n",
    "    print(score[layer].view(10,-1).shape)\n",
    "    print(grad_K.shape)\n",
    "    phi = (\n",
    "        K_params.detach().matmul(score[layer].view(10, -1)) + grad_K\n",
    "    ) / params.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 23, 256])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3,4])\n",
    "torch.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGD:\n",
    "    def __init__(self, kernel, optimizer):\n",
    "        self.K = kernel\n",
    "        self.optim = optimizer\n",
    "        self.params = [param for param in self.optim.param_groups[0][\"params\"]]\n",
    "\n",
    "    def backward(self, loss_function, **args):\n",
    "        loss = loss_function(**args)\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        score = [deepcopy(param.grad) for param in self.params]\n",
    "        phi_all = []\n",
    "\n",
    "        self.optim.zero_grad()\n",
    "        for layer, params in enumerate(self.params):\n",
    "            shape = params.shape\n",
    "            params = params.view(10, -1).detach().requires_grad_(True)\n",
    "\n",
    "            K_params = self.K(params, params.detach())\n",
    "            grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "            phi = (\n",
    "                K_params.detach().matmul(score[layer].reshape(10, -1)) + grad_K\n",
    "            ) / params.size(0)\n",
    "\n",
    "            phi_all.append(phi.reshape(shape))\n",
    "        # params = [param.view(10,-1).detach().requires_grad_(True) for param in self.params]\n",
    "\n",
    "        # K_params = self.K(params, params.detach())\n",
    "        # grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "\n",
    "        # phi = (K_params.detach().matmul(score_function) + grad_K) / params.size(0)\n",
    "\n",
    "        self.phi = phi_all\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "torch.Size([10, 137985])\n",
      "tensor(1.2654e-13)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "params = torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "params.retain_grad()\n",
    "K_params = K(params, params.detach())\n",
    "K_params.sum().backward()\n",
    "print(params.grad.shape)\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "grads = [param.grad for param in optimizer.param_groups[0]['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-9.4986e-07)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "params = torch.cat([param.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "params.retain_grad()\n",
    "\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1)\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "critic_loss.backward()\n",
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].mean())\n",
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n"
     ]
    }
   ],
   "source": [
    "print([param.grad for param in optimizer.param_groups[0]['params']][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([10, 23, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 256]),\n",
       " torch.Size([10, 1, 256]),\n",
       " torch.Size([10, 256, 1]),\n",
       " torch.Size([10, 1, 1])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = [param.shape for param in optimizer.param_groups[0]['params']]\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5888, 256, 65536, 256, 65536, 256, 256, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = tuple([int(param.numel()/10) for param in optimizer.param_groups[0]['params']])\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(-0.0002)\n",
      "tensor(-3.1934e-05)\n",
      "tensor(-3.1934e-05)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "print(optimizer.param_groups[0]['params'][0].grad.mean())\n",
    "\n",
    "actions = torch.stack([torch.randn(6) for i in range(10)], dim=0)\n",
    "states = torch.randn(17).repeat(10, 1)\n",
    "q_target = torch.randn(10,1).detach()\n",
    "q_values = critic(states, actions)\n",
    "\n",
    "# [ensemble_size, batch_size] - [1, batch_size]\n",
    "critic_loss = ((q_values - q_target.view(1, -1)) ** 2).mean(dim=1).sum(dim=0)\n",
    "\n",
    "critic_loss.backward()\n",
    "\n",
    "score = torch.cat([param.grad.view(param.size(0),-1) for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "print(score.mean())\n",
    "optimizer.zero_grad()\n",
    "\n",
    "params=torch.cat([param.view(param.size(0),-1) for param in optimizer.param_groups[0]['params']], dim=1).detach().requires_grad_()\n",
    "K_params = K(params, params.detach())\n",
    "grad_K = -torch.autograd.grad(K_params.sum(), params)[0]\n",
    "phi = (\n",
    "    K_params.detach().matmul(score) + grad_K\n",
    ") / params.size(0)\n",
    "print(phi.mean())\n",
    "\n",
    "lengths = tuple([int(param.numel()/param.size(0)) for param in optimizer.param_groups[0]['params']])\n",
    "\n",
    "for param, phi in zip(optimizer.param_groups[0]['params'], torch.split(phi, lengths, dim=1)):\n",
    "    param.grad = phi.reshape(param.shape)\n",
    "print(torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 23, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 256])\n",
      "torch.Size([10, 1, 256])\n",
      "torch.Size([10, 256, 1])\n",
      "torch.Size([10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for tensor, shape in zip(torch.split(params, lengths, dim=1), shapes):\n",
    "    tensor=tensor.reshape(shape)\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 137985])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([param.grad.view(10,-1) for param in optimizer.param_groups[0]['params']], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error. Trying to rebuild mujoco_py.\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder\u001b[39;00m \u001b[39mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerated\u001b[39;00m \u001b[39mimport\u001b[39;00m const\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:504\u001b[0m\n\u001b[1;32m    503\u001b[0m mujoco_path \u001b[39m=\u001b[39m discover_mujoco()\n\u001b[0;32m--> 504\u001b[0m cymj \u001b[39m=\u001b[39m load_cython_ext(mujoco_path)\n\u001b[1;32m    507\u001b[0m \u001b[39m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:111\u001b[0m, in \u001b[0;36mload_cython_ext\u001b[0;34m(mujoco_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m         cext_so_path \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39mbuild()\n\u001b[0;32m--> 111\u001b[0m         mod \u001b[39m=\u001b[39m load_dynamic_ext(\u001b[39m'\u001b[39;49m\u001b[39mcymj\u001b[39;49m\u001b[39m'\u001b[39;49m, cext_so_path)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m mod\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/mujoco_py/builder.py:130\u001b[0m, in \u001b[0;36mload_dynamic_ext\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    129\u001b[0m loader \u001b[39m=\u001b[39m ExtensionFileLoader(name, path)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mload_module()\n",
      "\u001b[0;31mImportError\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mHopper-v2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/registration.py:676\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake\u001b[39m(\u001b[39mid\u001b[39m: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEnv\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 676\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mmake(\u001b[39mid\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/registration.py:520\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspec(path)\n\u001b[1;32m    519\u001b[0m \u001b[39m# Construct the environment\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[39mreturn\u001b[39;00m spec\u001b[39m.\u001b[39;49mmake(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/registration.py:139\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_point(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n\u001b[1;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m load(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mentry_point)\n\u001b[1;32m    140\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Make the environment aware of which spec it came from.\u001b[39;00m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/registration.py:55\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Type:\n\u001b[1;32m     54\u001b[0m     mod_name, attr_name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(mod_name)\n\u001b[1;32m     56\u001b[0m     fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(mod, attr_name)\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco_env\u001b[39;00m \u001b[39mimport\u001b[39;00m MujocoEnv\n\u001b[1;32m      3\u001b[0m \u001b[39m# ^^^^^ so that user gets the correct error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# message if mujoco is not installed correctly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mant\u001b[39;00m \u001b[39mimport\u001b[39;00m AntEnv\n",
      "File \u001b[0;32m/disk/scratch1/adamjelley/miniconda3/envs/CORL/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     15\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m             e\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m DEFAULT_SIZE \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_observation_to_space\u001b[39m(observation):\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)"
     ]
    }
   ],
   "source": [
    "gym.make('Hopper-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin:/usr/lib/nvidia\n"
     ]
    }
   ],
   "source": [
    "%set_env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/afs/inf.ed.ac.uk/user/s21/s2139934/.mujoco/mujoco210/bin:/usr/lib/nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "173b67b242dc59c580e82c555e2ef8f010d22ca709f837bddfbc98404951b495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
